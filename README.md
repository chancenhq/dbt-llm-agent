# Ragstar — AI Data Analyst for dbt Projects

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.x-blue.svg)](https://www.typescriptlang.org/)
[![Docker Compose](https://img.shields.io/badge/built%20with-Docker%20Compose-blue.svg)](https://docs.docker.com/compose/)

> **Ragstar is in public βeta.** Expect rapid changes and occasional rough edges.

---

## 1. What is Ragstar?

Ragstar connects to your **dbt** project, builds a knowledge base from models & documentation, and lets everyone ask data-related questions in plain English via a beautiful web dashboard or Slack. Under the hood Ragstar combines:

- PostgreSQL + `pgvector` for fast similarity search
- Embeddings + LLMs (OpenAI, Anthropic, etc.) for reasoning
- A modern **Next.js** frontend & **Django** backend

### Screenshots

#### Dashboard

![Dashboard](docs/dashboard.png)

#### Integrations

![Integrations](docs/integrations.png)

#### Settings

![Settings](docs/settings.png)

---

## 2. Quick start (🚀 2 commands)

```bash
# ① clone & prepare env file
$ git clone https://github.com/pragunbhutani/ragstar.git && cd ragstar
$ cp .env.example .env && ${EDITOR:-vi} .env  # ⇒ edit just the vars shown below

# ② build & run everything
$ docker compose up --build -d
```

When the containers are healthy:

- Frontend: http://localhost:3000 (Next.js)
- API: http://localhost:8000 (Django/DRF)
- Flower: http://localhost:5555 (background tasks)

Run first-time Django tasks:

```bash
# inside the running backend container
$ docker compose exec backend-django \
    uv run python manage.py migrate
```

🎉 That's it — open http://localhost:3000, sign up for a new account and you're ready to start using Ragstar.

---

## 3. Environment variables

Only a handful of variables are truly **required** for a local/dev install. The rest are advanced overrides.

Ragstar keeps the default stack as lightweight as possible.  
For a **local `docker compose` run you only need 3 variables** – everything else has sane fall-backs.

### 3.1 Required for local/dev

| Var                   | Example                   | Purpose                                              |
| --------------------- | ------------------------- | ---------------------------------------------------- |
| `NEXTAUTH_SECRET`     | `openssl rand -base64 32` | Secret used by **next-auth** to sign session cookies |
| `NEXTAUTH_URL`        | `http://localhost:3000`   | Public URL where the frontend is reachable           |
| `NEXT_PUBLIC_API_URL` | `http://localhost:8000`   | Public URL of the Django API exposed to the browser  |

Create a `.env` file in the repo root and paste the three lines above (adjust URLs if you changed the ports).

### 3.2 Common overrides (optional)

| Var                                                                | Default                      | When you might set it                                                                                  |
| ------------------------------------------------------------------ | ---------------------------- | ------------------------------------------------------------------------------------------------------ |
| `INTERNAL_API_URL`                                                 | `http://backend-django:8000` | Only needed when the frontend talks to the backend across Docker networks or remote hosts.             |
| `ENVIRONMENT`                                                      | `local`                      | Switch between `local`, `development`, `production` behaviour inside Django settings.                  |
| `APP_HOST`                                                         | —                            | Extra hostname to append to Django `ALLOWED_HOSTS` & CORS lists, e.g. your public Ngrok / Vercel host. |
| `DATABASE_URL`                                                     | auto-generated by compose    | Point the backend & worker to your own Postgres instance.                                              |
| `CELERY_BROKER_URL`                                                | `redis://redis:6379/0`       | Use an external Redis / RabbitMQ instead of the bundled one.                                           |
| `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_DEFAULT_REGION` | not set                      | **Only required when you disable LocalStack and want to store secrets in real AWS Parameter Store.**   |

### 3.3 LLM Provider API Keys

You need to provide API keys for all the LLM providers you plan on using.

```bash
LLM_OPENAI_API_KEY=...
LLM_ANTHROPIC_API_KEY=...
LLM_GOOGLE_API_KEY=...
```

### 3.4 Postgres defaults (used by compose)

```bash
POSTGRES_DB=ragstar
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_PORT=5432
```

Set a single `EXTERNAL_POSTGRES_URL=<url>` to BYO Postgres (with the `pgvector` extension).

---

## 4. First-run onboarding

After logging into the dashboard you'll be guided through these steps:

1. **Add a dbt project** → _Projects › New_ (dbt **Cloud** recommended — just paste the service token). GitHub or local zip upload also supported.
2. **Pick the dbt models you want to use for answering questions** → choose which model to use for ∙ questions ∙ embeddings ∙ SQL verification.
3. **Configure Slack** (optional)
   - Go to _Integrations › Slack_.
   - Follow the inline manifest to create a Slack app.
   - Paste **Bot Token**, **Signing Secret**, **App Token**.
4. **Ask questions!** Use the chat on the dashboard or `/ask` in Slack.

> Other integrations (Metabase, Snowflake, MCP) are available under _Integrations_ but currently **βeta / experimental**. MCP server is temporarily disabled while we stabilise streaming support.

---

## 5 Managing the stack

Common operations are wrapped in one-liners:

```bash
# shell into backend or frontend
$ docker compose exec backend-django bash
$ docker compose exec frontend-nextjs sh

# tail logs
$ docker compose logs -f backend-django

# stop / remove containers
docker compose down          # keep volumes
docker compose down -v       # destroy DB
```

---

## 6. Local dev without Docker (advanced)

1. Install **Python 3.10+**, **Node 18+**, **uv**, **pnpm**, and Postgres16+ with `pgvector`.
2. `uv venv && source .venv/bin/activate && uv pip install -e backend_django/`
3. `pnpm install --filter frontend_nextjs`
4. Start services in two terminals:
   - **Backend** — `cd backend_django && uv run python manage.py runserver 0.0.0.0:8000`
   - **Frontend** — `cd frontend_nextjs && pnpm dev`
5. Export the same env vars listed above.

Docker is strongly recommended unless you're hacking on the codebase itself.

---

## 7. Contributing

We 💛 community PRs. Please file an issue first for major changes. Make sure `ruff`, `black`, `mypy`, and `eslint` pass before opening a pull request.

---

---

## 8. MCP Server Integration (Self-Hosted Only)

Ragstar includes a **Model Context Protocol (MCP)** server that allows LLM clients like Claude.ai to directly access your dbt knowledge base. The MCP server provides secure, OAuth-authenticated access to your dbt models and project information.

> **⚠️ Important:** The MCP server can only be used with **self-hosted/open source** deployments of Ragstar. This is due to the **1:1 relationship** between an MCP client and server — each client needs its own dedicated server instance.

### 8.1 What is the MCP Server?

The MCP server acts as a bridge between LLM clients (like Claude.ai) and your Ragstar knowledge base. It provides:

- **Secure OAuth 2.0 authentication** with PKCE
- **Organization-scoped access** to dbt models and projects
- **Real-time data access** without manual imports
- **Semantic search** capabilities across your dbt documentation
- **Detailed model information** including SQL, lineage, and metadata

### 8.2 Available MCP Tools

The MCP server exposes these tools to LLM clients:

- `list_dbt_models` — Browse and filter dbt models by project, schema, or materialization
- `search_dbt_models` — Semantic search for relevant models using natural language
- `get_model_details` — Get detailed information about specific models including SQL and lineage
- `get_project_summary` — Overview of connected dbt projects and their structure

### 8.3 Setting Up the MCP Server

#### Prerequisites

1. **Self-hosted Ragstar** running with Docker Compose
2. **dbt project connected** and models loaded in your knowledge base
3. **LLM client** that supports MCP (e.g., Claude.ai, ChatGPT with MCP support)

#### Configuration

The MCP server runs on port `8080` by default. Add these environment variables to your `.env` file:

```bash
# MCP Server Configuration
MCP_AUTHORIZATION_BASE_URL=http://localhost:8000  # Your Django backend URL
DJANGO_BACKEND_URL=http://localhost:8000          # Backend URL for MCP server
ALLOWED_ORIGINS=*                                 # Or specific origins for security
```

#### Starting the MCP Server

The MCP server is included in the Docker Compose stack:

```bash
# Start all services including MCP server
docker compose up -d

# Check MCP server health
curl http://localhost:8080/health
```

### 8.4 OAuth 2.0 Flow Explanation

The MCP server implements a complete OAuth 2.0 authorization flow with organization-scoped access. Here's how it works:

#### Flow Overview

```mermaid
sequenceDiagram
    participant Claude as Claude.ai
    participant MCP as MCP Server
    participant Django as Django Backend
    participant User as User Browser

    Claude->>MCP: 1. Request OAuth metadata
    MCP->>Django: 2. Proxy metadata request
    Django->>MCP: 3. Return OAuth configuration
    MCP->>Claude: 4. OAuth server metadata

    Claude->>MCP: 5. Authorization request (with PKCE)
    MCP->>Django: 6. Proxy authorization request
    Django->>User: 7. Redirect to frontend login
    User->>Django: 8. Authenticate via Next.js
    Django->>MCP: 9. Authorization code
    MCP->>Claude: 10. Return authorization code

    Claude->>MCP: 11. Exchange code for tokens
    MCP->>Django: 12. Validate and exchange
    Django->>MCP: 13. Access & refresh tokens
    MCP->>Claude: 14. JWT tokens

    Claude->>MCP: 15. API calls with Bearer token
    MCP->>Django: 16. Validate token & get user context
    Django->>MCP: 17. Organization-scoped data
    MCP->>Claude: 18. Formatted response
```

#### Key Components

1. **OAuth Metadata Discovery**: MCP server exposes RFC 8414 compliant metadata endpoints
2. **PKCE Security**: Uses Proof Key for Code Exchange for enhanced security
3. **Auto-Registration**: Automatically registers new OAuth clients (like Claude.ai)
4. **Organization Scoping**: All data access is automatically scoped to the user's organization
5. **JWT Tokens**: Secure, stateless authentication using JSON Web Tokens

#### Security Features

- **PKCE (Proof Key for Code Exchange)**: Prevents authorization code interception attacks
- **Organization Isolation**: Users can only access their organization's data
- **Token Validation**: All API calls require valid JWT tokens
- **Automatic Expiry**: Access tokens expire after 1 hour, refresh tokens after 7 days

### 8.5 Connecting Claude.ai to Your MCP Server

#### Step 1: Configure MCP in Claude.ai

1. Go to Claude.ai settings
2. Find the "MCP Servers" or "Model Context Protocol" section
3. Add a new server with these details:
   - **Server URL**: `http://localhost:8080` (or your public URL)
   - **OAuth**: Enable OAuth 2.0 authentication
   - **Auto-discovery**: Enable to automatically discover capabilities

#### Step 2: Authorize the Connection

1. Claude.ai will redirect you to your Ragstar login page
2. Sign in with your Ragstar account
3. You'll be redirected back to Claude.ai with authorization
4. The connection will be linked to your organization

#### Step 3: Start Using MCP Tools

You can now ask Claude.ai to:

- "List all my dbt models"
- "Search for revenue-related models"
- "Show me details about the customer_metrics model"
- "What dbt projects do I have connected?"

### 8.6 Example MCP Interactions

#### Listing Models

```
You: "What dbt models do I have available?"
Claude: [Calls list_dbt_models tool]
Claude: "You have 23 dbt models across 2 projects:
- analytics_prod: 15 models (staging, marts schemas)
- marketing_analytics: 8 models (staging, reporting schemas)
..."
```

#### Searching Models

```
You: "Find models related to customer revenue"
Claude: [Calls search_dbt_models with "customer revenue"]
Claude: "I found 3 relevant models:
- customer_revenue_monthly (similarity: 0.95)
- customer_ltv_calculation (similarity: 0.87)
- revenue_attribution (similarity: 0.82)
..."
```

#### Getting Model Details

```
You: "Show me the SQL for customer_revenue_monthly"
Claude: [Calls get_model_details for "customer_revenue_monthly"]
Claude: "Here's the customer_revenue_monthly model:
- Schema: marts
- Materialization: table
- SQL: SELECT customer_id, DATE_TRUNC('month', order_date) as month, SUM(amount) as revenue FROM..."
```

### 8.7 Troubleshooting MCP Connection

#### Common Issues

1. **Authentication Fails**: Check that your Ragstar backend is accessible and you're logged in
2. **No Models Found**: Ensure your dbt project is connected and models are loaded
3. **Permission Errors**: Verify the user has access to the organization's dbt projects
4. **Network Issues**: Check firewall settings and port accessibility

#### Debug Commands

```bash
# Check MCP server health
curl http://localhost:8080/health

# Test OAuth metadata
curl http://localhost:8080/.well-known/oauth-authorization-server

# View MCP server logs
docker compose logs -f mcp-server
```

### 8.8 Production Deployment

For production use:

1. **Use HTTPS**: Configure SSL certificates for secure connections
2. **Restrict Origins**: Set specific allowed origins instead of `*`
3. **Monitor Usage**: Track OAuth token usage and API calls
4. **Scale Considerations**: Each client needs its own server instance

### 8.9 Limitations

- **1:1 Client-Server Relationship**: Each MCP client needs its own server instance
- **Organization Scoping**: Users can only access their own organization's data
- **Token Expiry**: Access tokens expire after 1 hour (refresh tokens after 7 days)
- **Self-Hosted Only**: Not available in hosted/SaaS deployments

---

## 9. Contributing

We 💛 community PRs. Please file an issue first for major changes. Make sure `ruff`, `black`, `mypy`, and `eslint` pass before opening a pull request.

---

## 10. License

Ragstar is released under the MIT License — see [LICENSE](./LICENSE).

---

## 99. OLD DOCS

### Option 1: Docker Compose (Recommended)

1.  **Clone the repository:**

    ```bash
    git clone https://github.com/pragunbhutani/ragstar.git
    cd ragstar
    ```

2.  **Set up environment variables:**
    Rename `.env.example` to `.env` and populate it with your specific configurations, such as your OpenAI API key and the `APP_HOST` (e.g., `localhost` or your server's IP address).

    ```bash
    cp .env.example .env
    # Open .env and fill in your values
    ```

3.  **Configure Ragstar rules:**
    Rename `.ragstarrules.example.yml` to `.ragstarrules.yml`. This file allows you to define custom instructions and behaviors for your RAG application.

    ```bash
    cp .ragstarrules.example.yml .ragstarrules.yml
    # Open .ragstarrules.yml and customize if needed
    ```

4.  **Build and run with Docker Compose:**
    This command will build the Docker images and start the application in detached mode.

    ```bash
    docker compose up --build -d
    ```

5.  **Run initial Django commands:**
    Execute these commands in the `app` container to set up the database and create an admin user.

    ```bash
    docker compose exec app uv run python manage.py migrate
    docker compose exec app uv run python manage.py createsuperuser # Follow prompts to create your admin user
    ```

6.  **Initialize your project:**
    This command sets up the necessary project configurations. You can choose between `cloud`, `core`, or `local` methods.

    ```bash
    docker compose exec app uv run python manage.py init_project --method cloud
    # Or --method core, or --method local
    ```

7.  **Access the Django Admin:**
    Open your web browser and navigate to `http://<your_APP_HOST_value>/admin` (e.g., `http://localhost/admin` if `APP_HOST=localhost`).
    Log in with the superuser credentials you created.

8.  **Embed Models:**
    In the Django admin interface, you can:
    - Navigate to "Models".
    - Click on "Interpret".
    - Select and embed the models you want to use for answering questions.

### Option 2: Local Python Environment (Advanced)

If you prefer not to use Docker, you can set up a local Python environment.

1.  **Prerequisites:**

    - Python 3.10 or higher.
    - `uv` (Python package installer and virtual environment manager). You can install it from [https://github.com/astral-sh/uv](https://github.com/astral-sh/uv).
    - A running PostgreSQL server (version 11+) with the `pgvector` extension enabled.

2.  **Check Python Version:**

    ```bash
    python --version # or python3 --version
    ```

3.  **Clone Repository:**

    ```bash
    git clone https://github.com/pragunbhutani/ragstar.git
    cd ragstar
    ```

4.  **Create a virtual environment and install dependencies:**

    ```bash
    # Create a virtual environment (e.g., named .venv)
    python -m venv .venv
    # Or using uv: uv venv

    # Activate the virtual environment
    source .venv/bin/activate # On Windows: .venv\Scripts\activate

    # Install dependencies using uv
    uv pip install -r requirements.txt
    # Or if you have a pyproject.toml configured for uv:
    # uv pip install -e .
    ```

5.  **Set up PostgreSQL:**

    - Install PostgreSQL and `pgvector`.
    - Create a database (e.g., `ragstar_local_dev`).
    - Enable the `pgvector` extension in the database:
      ```sql
      -- Run in psql connected to your database
      CREATE EXTENSION IF NOT EXISTS vector;
      ```

6.  **Configure Environment Variables:**
    Copy the example environment file and fill in your details:

    ```bash
    cp .env.example .env
    ```

    Edit `.env`:

    - **Required:** Set your `OPENAI_API_KEY`.
    - **Required:** Set `DATABASE_URL` to your local PostgreSQL connection string (e.g., `postgresql://user:password@host:port/dbname`). Ensure this matches the database you created. (The `.env.example` might have fallback variables like `DB_NAME_FALLBACK`, etc., which are used if `DATABASE_URL` is not set; for local setup, explicitly setting `DATABASE_URL` is clearer).
    - **Required:** Set `APP_HOST` (e.g., `localhost` or `127.0.0.1`).
    - **Ragstar Rules:** Rename `.ragstarrules.example.yml` to `.ragstarrules.yml` and customize if needed.
    - **Slack (Optional):** Configure `INTEGRATIONS_SLACK_BOT_TOKEN` and `INTEGRATIONS_SLACK_SIGNING_SECRET` if you plan to use the Slack integration.
    - **Other:** Review other variables like `RAGSTAR_LOG_LEVEL`, etc., and adjust if needed.

7.  **Run Database Migrations:**
    Apply database schema changes:

    ```bash
    uv run python manage.py migrate
    ```

8.  **Create a Superuser:**
    Create an admin account to access the Django admin interface:

    ```bash
    uv run python manage.py createsuperuser
    # Follow the prompts
    ```

9.  **Initialize your project:**
    This command sets up the necessary project configurations.

    ```bash
    uv run python manage.py init_project --method cloud
    # Or --method core, or --method local, depending on your dbt project setup.
    ```

9b.  **[dbt core] Initialize your project:**
    If you use `dbt` core you might need to set up adapters.  Sample below for PostgreSQL.

    ```bash
    uv pip install dbt-core dbt-postgres
    uv run python manage.py init_project --method core
    ```

10. **Run the Development Server:**

    ```bash
    uv run python manage.py runserver
    ```

    The application will typically be available at `http://<your_APP_HOST_value>:8000` (e.g., `http://localhost:8000`).

11. **Access the Django Admin & Embed Models:**
    Follow the same steps as in the Docker setup (steps 7 and 8) to access the admin interface (`http://<your_APP_HOST_value>:8000/admin`) and embed your models.

## Usage

After setup and initialization, you can interact with Ragstar.

### Using Docker Compose:

Most Django `manage.py` commands should be run **inside the `app` container** using `docker compose exec`:

```bash
# Example: Run database migrations (if not already done by entrypoint)
docker compose exec app uv run python manage.py migrate

# Example: Create a superuser (if not done during initial setup)
docker compose exec app uv run python manage.py createsuperuser

# Example: Initialize project
docker compose exec app uv run python manage.py init_project --method cloud
```

The application server is started automatically by `docker compose up`. Access it via `http://<your_APP_HOST_value>/admin`.

### Using Local Python Environment:

Run Django `manage.py` commands directly using `uv run` from your activated virtual environment:

```bash
# Example: Run the development server
uv run python manage.py runserver

# Example: Create a superuser
uv run python manage.py createsuperuser

# Example: Initialize project
uv run python manage.py init_project --method cloud
```

Access the application at `http://<your_APP_HOST_value>:8000` and the admin interface at `http://<your_APP_HOST_value>:8000/admin`.

### Core Django Management Commands

The primary way to manage and interact with the application (outside of the web interface) is through Django's `manage.py` script. Here are some key commands:

- **`uv run python manage.py migrate`**: Applies database migrations.
- **`uv run python manage.py createsuperuser`**: Creates an administrator account.
- **`uv run python manage.py init_project --method <cloud|core|local>`**: Initializes Ragstar with your project data (e.g., from dbt). This is crucial for setting up the knowledge base.
- **`uv run python manage.py runserver [host:port]`**: Starts the Django development web server.

Other functionalities, such as interpreting and embedding models, are primarily handled through the Django admin interface after logging in.

## Slack Integration (Optional)

Ragstar provides a Slack manifest to easily integrate its functionalities into your Slack workspace.

1.  Ensure `INTEGRATIONS_SLACK_SIGNING_SECRET` and `INTEGRATIONS_SLACK_BOT_TOKEN` are set in your `.env` file.
2.  Use the `.slack_manifest.example.json` file as a template to create a new Slack app.
3.  Follow Slack's documentation for creating an app from a manifest.
4.  This will enable features like asking questions and receiving answers directly within Slack (assuming the Slack integration is running as part of the Django application).

## Contributing

Contributions are welcome! Please follow standard fork-and-pull-request workflow.

## License

[MIT License](https://opensource.org/licenses/MIT)
